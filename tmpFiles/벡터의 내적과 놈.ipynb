{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac74b8c",
   "metadata": {},
   "source": [
    "# 벡터의 내적과 놈\n",
    "\n",
    "벡터의 내적과 놈의 의의와 계산 방법을 배웁니다. 벡터의 조작에 익숙해집시다.\n",
    "\n",
    "## 내적\n",
    "\n",
    "내적은 벡터끼리의 곱의 한 종류인데 다음과 같이 각 요소끼리 곱한 값을 총합해서 정의합니다.\n",
    "\n",
    "$$\n",
    "\\vec{a} = (a_1,a_2,\\cdots,a_n)\n",
    "\\vec{b} = (b_1,b_2,\\cdots,b_n)\n",
    "$$\n",
    "\n",
    "위와 같을 때, $$\\vec{a} . \\vec{b}$$ 로 표시되게 하면 다음과 같습니다.\n",
    "\n",
    "$$\n",
    "\\vec{a} \\cdot \\vec{b} = (a_1,a_2,\\cdots,a_n) \\cdot (b_1,b_2,\\cdots,b_n)\\\\\n",
    "= (a_1b_1 + a_2b_2 + \\cdot + a_nb_n) \\\\\n",
    "= \\sum_{k=1}^{n}{a_kb_k}\n",
    "$$\n",
    "\n",
    "내적을 구할 때는 두 개의 벡터의 요소 수가 같아야 합니다. 내적은 삼각함수를 사용해 구하는 방법이 있는데 이것에 대해선 나중에 설명합니다.\n",
    "\n",
    "## 내적의 구현\n",
    "\n",
    "내적은 numpy의 **dot()** 함수로 간단하게 구할 수 있습니다. 또한 **sum()** 함수를 사용해서 각 요소의 곱의 총합으로도 구할 수도 있습니다.\n",
    "\n",
    "양쪽을 비교해 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fbc189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- dot() 함수 --\n",
      "10\n",
      "--- 곱의 총합 --\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([3,2,1])\n",
    "\n",
    "print(\"-- dot() 함수 --\")\n",
    "print(np.dot(a,b)) # dot() 함수에 의한 내적\n",
    "print(\"--- 곱의 총합 --\") #\n",
    "print(np.sum(a*b)) # 곱의 총합에 의한 내적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff5273",
   "metadata": {},
   "source": [
    "**dot()** 함수, 곱의 총합 모두 같은 결과가 나왔습니다. 내적은 예를 들어 두 개 벡터의 상관관계를 구할 때 등에 사용합니다. \n",
    "\n",
    "## 놈\n",
    "\n",
    "놈은 벡터의 \"크기\"를 나타내는 양입니다. 인공지능에서 자주 쓰이는 놈으로는 $$L^2$$놈과 $$L^1$$놈이 있습니다.\n",
    "\n",
    "### $$L^2$$놈\n",
    "\n",
    "$$L^2$$ 놈은 다음과 같이 $$ ||\\vec{x}||{_2} $$로 나타냅니다. 벡터의 각 요소를 제곱하여 제곱근을 구해 계산합니다.\n",
    "\n",
    "$$\n",
    "|| \\vec{x}||{_2} = \\sqrt{x_1^2 + x_2^2 + \\cdot + x_n^2} \\\\\n",
    "= \\sqrt{\\sum_{k=1}^{n}{x_k^2}}\n",
    "$$\n",
    "\n",
    "### $$L^1$$ 놈\n",
    "\n",
    "\n",
    "$$L^1$$ 놈은 다음과 같이 $$ ||\\vec{x}||{_1} $$ 로 나타냅니다. 벡터의 각 요소의 절대값을 더해서 계산합니다.\n",
    "\n",
    "\n",
    "$$\n",
    "\\vec x_1 = |x_1| + |x_2| + ...  + |x_n| \\\\\n",
    "= \\sum_{k=1}^n x_k\n",
    "$$\n",
    "\n",
    "\n",
    "### 일반화된 놈\n",
    "\n",
    "놈을 더욱 일반화한 $$L^p$$놈은 다음과 같이 나타냅니다\n",
    "\n",
    "$$\n",
    "||\\vec{x}||_p = (x_1^p + x_2^p + \\cdot + x_n^p)^\\frac{1}{p} \\\\\n",
    "= (\\sum_{k=1}^{n}{x_k^p})^\\frac{1}{p}\n",
    "$$\n",
    "\n",
    "놈에는 몇 가지 표시법이 있는데 인공지능에서는 이것들을 필요에 따라 구분해서 사용합니다.\n",
    "\n",
    "### 놈의 구현\n",
    "\n",
    "놈은 numpy의 **linalg.norm()** 함수를 이용해서 구할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a904e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--L2놈--\n",
      "2.0\n",
      "--L1놈--\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,1,-1,-1])\n",
    "\n",
    "print(\"--L2놈--\")\n",
    "print(np.linalg.norm(a)) # L2놈 (디폴트)\n",
    "print(\"--L1놈--\") \n",
    "print(np.linalg.norm(a,1)) # L1놈\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87864b85",
   "metadata": {},
   "source": [
    "이상과 같이, 놈의 종류에 따라 벡터의 \"크기\"는 다른 값이 됩니다.\n",
    "높은 인공지능에서 **정칙화**에 쓰입니다. 정칙화란 필요 이상으로 네트워크 합슥이 진행되는 것을 파라미터를 조절해서 예방하는 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
